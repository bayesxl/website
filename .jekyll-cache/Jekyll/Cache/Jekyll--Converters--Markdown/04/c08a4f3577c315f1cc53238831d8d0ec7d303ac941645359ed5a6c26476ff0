I"+$<h2 id="contents">Contents</h2>

<ul>
  <li><a href="#ConfJour">Conference &amp; Journal Papers</a></li>
  <li><a href="#Preprints">Preprints</a></li>
  <li><a href="#Workshop">Workshop Papers</a></li>
  <li><a href="#Theses">Theses</a></li>
</ul>

<h2 id="conference--journal-papers"><a name="ConfJour">Conference &amp; Journal Papers</a></h2>

<ol class="bibliography"><li><span id="cohen2020pessimism">Cohen, M. K., &amp; Hutter, M. (2020). Pessimism About Unknown Unknowns Inspires Conservatism. <i>Conference on Learning Theory</i>, 1–30. https://pdfs.semanticscholar.org/cece/bc0c325a9fc58e78d82a42c8b3f2d9bce769.pdf</span>

<span id="cohen2020pessimism_materials">
  <ul class="nav nav-pills">
    
    <li><a class="bib-materials" data-target="#cohen2020pessimism_abstract" data-toggle="collapse" href="#cohen2020pessimism" onclick="return false">Abstract</a></li>
    

    <li><a class="bib-materials" data-target="#cohen2020pessimism_bibtex" data-toggle="collapse" href="#cohen2020pessimism" onclick="return false">Bib</a></li>

    
    <!-- /~mosb doesn't seem to work, but /~mosb/ does: I don't know why -->
    <li><a class="bib-materials" href="/~mosb/public/pdf/cohen2020pessimism.pdf">PDF</a></li>
    

    
    <li><a class="bib-materials" href="https://pdfs.semanticscholar.org/cece/bc0c325a9fc58e78d82a42c8b3f2d9bce769.pdf">web</a></li>
    

    

    

    
  </ul>

  
  <p id="cohen2020pessimism_abstract" class="collapse">If we could define the set of all bad outcomes, we could hard-code an agent which avoids them; however, in sufficiently complex environments, this is infeasible. We do not know of any general-purpose approaches in the literature to avoiding novel failure modes. Motivated by this, we define an idealized Bayesian reinforcement learner which follows a policy that maximizes the worst-case expected reward over a set of world-models. We call this agent pessimistic, since it optimizes assuming the worst case. A scalar parameter tunes the agent’s pessimism by changing the size of the set of world-models taken into account. Our first main contribution is: given an assumption about the agent’s model class, a sufficiently pessimistic agent does not cause “unprecedented events” with probability 1-δ, whether or not designers know how to precisely specify those precedents they are concerned with. Since pessimism discourages exploration, at each timestep, the agent may defer to a mentor, who may be a human or some known-safe policy we would like to improve. Our other main contribution is that the agent’s policy’s value approaches at least that of the mentor, while the probability of deferring to the mentor goes to 0. In high-stakes environments, we might like advanced artificial agents to pursue goals cautiously, which is a non-trivial problem even if the agent were allowed arbitrary computing power; we present a formal solution.</p>
  

  <pre id="cohen2020pessimism_bibtex" class="pre pre-scrollable collapse">@inproceedings{cohen2020pessimism,
  title = {Pessimism About Unknown Unknowns Inspires Conservatism},
  url = {https://pdfs.semanticscholar.org/cece/bc0c325a9fc58e78d82a42c8b3f2d9bce769.pdf},
  language = {en},
  booktitle = {Conference on Learning Theory},
  author = {Cohen, Michael K and Hutter, Marcus},
  year = {2020},
  pages = {1--30},
  file = {cohen2020pessimism.pdf}
}
</pre>

</span>
</li>
<li><span id="nguyen2020knowing">Nguyen, V., &amp; Osborne, M. (2020). Knowing The What But Not The Where in Bayesian Optimization. <i>International Conference on Machine Learning</i>.</span>

<span id="nguyen2020knowing_materials">
  <ul class="nav nav-pills">
    
    <li><a class="bib-materials" data-target="#nguyen2020knowing_abstract" data-toggle="collapse" href="#nguyen2020knowing" onclick="return false">Abstract</a></li>
    

    <li><a class="bib-materials" data-target="#nguyen2020knowing_bibtex" data-toggle="collapse" href="#nguyen2020knowing" onclick="return false">Bib</a></li>

    
    <!-- /~mosb doesn't seem to work, but /~mosb/ does: I don't know why -->
    <li><a class="bib-materials" href="/~mosb/public/pdf/nguyen2020knowing.pdf">PDF</a></li>
    

    
    <li><a class="bib-materials" href="">web</a></li>
    

    
    <li><a class="bib-materials" href="Link to github code, if there is code">code</a></li>
    

    

    
  </ul>

  
  <p id="nguyen2020knowing_abstract" class="collapse">Bayesian optimization has demonstrated impressive success in finding the optimum input x and
output f* = f(x*) = max f(x) of a black-box function f. In some applications, however, the optimum output f*
is known in advance and the goal is to find the corresponding optimum input
x*. In this paper, we consider a new setting in BO in which the knowledge of the optimum output f is available. Our goal is to exploit the
knowledge about f* to search for the input x* efficiently. To achieve this goal, we first transform the Gaussian process surrogate using the information
about the optimum output. Then, we propose two acquisition functions, called confidence bound minimization and expected regret minimization. We show that our approaches work intuitively and give quantitatively better performance against
standard BO methods. We demonstrate real applications in tuning a deep reinforcement learning algorithm on the CartPole problem and XGBoost on Skin Segmentation dataset in which the optimum values are publicly available.</p>
  

  <pre id="nguyen2020knowing_bibtex" class="pre pre-scrollable collapse">@inproceedings{nguyen2020knowing,
  title = {Knowing The What But Not The Where in Bayesian Optimization},
  url = {},
  language = {en},
  urldate = {},
  booktitle = {International Conference on Machine Learning},
  author = {Nguyen, Vu and Osborne, Michael},
  year = {2020},
  note = {Link to github code, if there is code},
  pages = {},
  file = {nguyen2020knowing.pdf}
}
</pre>

</span>
</li></ol>

<h2 id="preprints"><a name="Preprints">Preprints</a></h2>

<ol class="bibliography"></ol>

<h2 id="workshop-papers"><a name="Workshop">Workshop papers</a></h2>

<ol class="bibliography"></ol>

<h2 id="theses"><a name="Theses">Theses</a></h2>

<ol class="bibliography"><li><span id="osborne_bayesian_2010">Osborne, M. (2010). <i>Bayesian Gaussian Processes for Sequential Prediction, Optimisation and Quadrature</i> [PhD thesis]. PhD thesis, University of Oxford.</span>

<span id="osborne_bayesian_2010_materials">
  <ul class="nav nav-pills">
    
    <li><a class="bib-materials" data-target="#osborne_bayesian_2010_abstract" data-toggle="collapse" href="#osborne_bayesian_2010" onclick="return false">Abstract</a></li>
    

    <li><a class="bib-materials" data-target="#osborne_bayesian_2010_bibtex" data-toggle="collapse" href="#osborne_bayesian_2010" onclick="return false">Bib</a></li>

    
    <!-- /~mosb doesn't seem to work, but /~mosb/ does: I don't know why -->
    <li><a class="bib-materials" href="/~mosb/public/pdf/2160/full_thesis.pdf">PDF</a></li>
    

    

    

    

    
  </ul>

  
  <p id="osborne_bayesian_2010_abstract" class="collapse">We develop a family of Bayesian algorithms built around Gaussian processes for various problems posed by sensor networks. We firstly introduce an iterative Gaussian process for multi-sensor inference problems, and show how our algorithm is able to cope with data that may be noisy, missing, delayed and/or correlated. Our algorithm can also effectively manage data that features changepoints, such as sensor faults. Extensions to our algorithm allow us to tackle some of the decision problems faced in sensor networks, including observation scheduling. Along these lines, we also propose a general method of global optimisation, Gaussian process global optimisation (GPGO), and demonstrate how it may be used for sensor placement.

Our algorithms operate within a complete Bayesian probabilistic framework. As such, we show how the hyperparameters of our system can be marginalised by use of Bayesian quadrature, a principled method of approximate integration. Similar tech niques also allow us to produce full posterior distributions for any hyperparameters of interest, such as the location of changepoints. We frame the selection of the positions of the hyperparameter samples required by Bayesian quadrature as a decision prob lem, with the aim of minimising the uncertainty we possess about the values of the integrals we are approximating. Taking this approach, we have developed sampling for Bayesian quadrature (SBQ), a principled competitor to Monte Carlo methods.

We conclude by testing our proposals on real weather sensor networks. We further benchmark GPGO on a wide range of canonical test problems, over which it achieves a significant improvement on its competitors. Finally, the efficacy of SBQ is demonstrated in the context of both prediction and optimisation.</p>
  

  <pre id="osborne_bayesian_2010_bibtex" class="pre pre-scrollable collapse">@phdthesis{osborne_bayesian_2010,
  title = {Bayesian {Gaussian} {Processes} for {Sequential} {Prediction}, {Optimisation} and {Quadrature}},
  school = {PhD thesis, University of Oxford},
  author = {Osborne, Michael},
  year = {2010},
  file = {2160/full_thesis.pdf}
}
</pre>

</span>
</li></ol>

:ET